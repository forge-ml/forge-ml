const serverUrl = process.env.FORGE_LOCAL_SERVER || "https://api.forge.ai";

// Any code above this line will be ignored by a file loading boilerplate
// --- START -- //

/** THIS IS A GENERATED FILE, EDITS WILL BE OVERWRITTEN */

type ClientOptions = {
  forgeKey: string;
  //   defaultModel: string;
};

type RequestOptions = {
  token?: string;
  cache?: "Bust" | "Evade"; // (@TODO: only if cache setting)
  model?: string;
};

// Options that will be set at generation time
type GeneratedOptions =
  | {
      username: string;
      path: string;
      contentType?: "text";
    }
  | {
      username: string;
      path: string;
      contentType: "image";
    };

type ImageQuery = { imageUrl: string; prompt: string };

type QueryType = string | ImageQuery;

export const createRequest = <T>(params: GeneratedOptions) => {
  return async (query: QueryType, opts: RequestOptions) => {
    const baseController = (() => {
      switch (params.contentType) {
        case "image":
          return "image";
        default:
          return "q";
      }
    })();
    try {
      const response = await fetch(
        `${serverUrl}/${baseController}/${params.username}/${params.path}`,
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${opts.token}`,
            ...(opts.cache && {
              "Cache-Behavior": opts.cache,
              ...(opts.model && {
                Model: opts.model,
              }),
            }),
            ...(opts.model && {
              "X-Custom-Model": opts.model,
            }),
          },
          body: JSON.stringify({
            q: query,
          }),
        }
      );

      return response.json() as Promise<T>;
    } catch (error) {
      return { error: error } as T;
    }
  };
};

enum Provider {
  OpenAI = "openai",
  Anthropic = "anthropic",
  Groq = "groq",
}

type ModelConfig = {
  model: string;
  provider: Provider;
};

type RAGRequestOptions = {
  collectionId: string;
  token?: string;
  modelConfig?: ModelConfig;
  chunkCount?: number;
};

type Chunk = {
  text: string;
  score: number;
};

type RAGResponse = Promise<{
  response: string;
  context: Chunk[];
}>;

const ragRequest = async (
  query: string,
  opts: RAGRequestOptions
): RAGResponse => {
  const response = await fetch(`${serverUrl}/q/rag`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${opts.token}`,
    },
    body: JSON.stringify({
      q: query,
      collectionId: opts.collectionId,
      model: opts.modelConfig?.model,
      provider: opts.modelConfig?.provider,
      chunkCount: opts.chunkCount,
    }),
  });

  return response.json();
};

const Forge = (options: ClientOptions) => {
  const forgeKey = options.forgeKey;
  //   const defaultModel = options.defaultModel;

  const client = generatedClient(forgeKey);

  return client;
};

export default Forge;

// --- END -- //
// Any code below this line will be ignored by a file loading boilerplate

const generatedClient = (forgeKey: string) => {
  return {
    $withContext: (prompt: string, opts: RAGRequestOptions) => {
      return ragRequest(prompt, {
        token: opts.token || forgeKey,
        collectionId: opts.collectionId,
        modelConfig: opts.modelConfig,
        chunkCount: opts.chunkCount,
      });
    },
    text: {
      query: (prompt: string, opts?: RequestOptions) => {
        return createRequest({
          username: "${username}",
          path: "${path}",
        })(prompt, {
          token: opts?.token || forgeKey,
          cache: opts?.cache,
          model: opts?.model,
        });
      },
    },
    image: {
      queryImage: (
        prompt: { imageUrl: string; prompt: string },
        opts?: RequestOptions
      ) => {
        return createRequest({
          username: "${username}",
          path: "${path}",
          contentType: "image",
        })(prompt, {
          token: opts?.token || forgeKey,
          // cache: opts?.cache,
        });
      },
    },
  };
};
